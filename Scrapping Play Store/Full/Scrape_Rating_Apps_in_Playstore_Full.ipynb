{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QokQ8g0mivf5"
      },
      "outputs": [],
      "source": [
        "!pip install google-play-scraper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google_play_scraper import app\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "rrqLrNfIjPZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google_play_scraper import Sort, reviews\n",
        "\n",
        "result, continuation_token = reviews(\n",
        "    'com.', # Use apps id to scrape target apps\n",
        "    lang='id', # Use your language\n",
        "    country='id', # Use your country\n",
        "    sort=Sort.MOST_RELEVANT,\n",
        "    count=1000, # You can modify this with the amount of data you want to retrieve\n",
        "    filter_score_with=None # You can use to filter with rating 1,2,3,4 or 5 or use None to get all\n",
        ")"
      ],
      "metadata": {
        "id": "1AfTIZbzjdKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_busu = pd.DataFrame(np.array(result), columns=['review'])\n",
        "df_busu = df_busu.join(pd.DataFrame(df_busu.pop('review').tolist()))\n",
        "df_busu.head()"
      ],
      "metadata": {
        "id": "CnlEt4oRkJnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_busu.index)"
      ],
      "metadata": {
        "id": "Sjpvdn9iktwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_busu[['userName', 'score', 'at', 'content']].head()"
      ],
      "metadata": {
        "id": "jY1TNZFYk-2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df_busu[['userName', 'score', 'at', 'content']]\n",
        "sorted_df = new_df.sort_values(by='at', ascending=False)\n",
        "sorted_df.head()"
      ],
      "metadata": {
        "id": "aR4GgVIXln_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df = sorted_df[['userName', 'score', 'at', 'content']]"
      ],
      "metadata": {
        "id": "gmEA_N8JmD3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df = my_df[['content', 'score']]"
      ],
      "metadata": {
        "id": "HlU8DpccmPnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df.head()"
      ],
      "metadata": {
        "id": "hK1wXeeUmW08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def labelling(score):\n",
        "  if score < 3:\n",
        "    return 'Negative'\n",
        "  elif score == 4:\n",
        "    return 'Positive'\n",
        "  elif score == 5:\n",
        "    return 'Positive'\n",
        "\n",
        "my_df['Label'] = my_df['score'].apply(labelling)\n",
        "my_df.head(50)"
      ],
      "metadata": {
        "id": "MdBdzdugmwNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df.to_csv('scrapped_data.csv', index=False)"
      ],
      "metadata": {
        "id": "--JYNU1jo8JD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_column', None)\n",
        "my_df = pd.read_csv('/content/scrapped_data.csv')\n",
        "my_df.head(50)"
      ],
      "metadata": {
        "id": "DFLX0dYQpIc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df.info()"
      ],
      "metadata": {
        "id": "W5QluNdZpfHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df.isna()"
      ],
      "metadata": {
        "id": "HP3iIIMKpvkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df.isna().any()"
      ],
      "metadata": {
        "id": "5rk-SswLp4rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df.describe()"
      ],
      "metadata": {
        "id": "XcQhsdccp9cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df.isnull().sum()"
      ],
      "metadata": {
        "id": "V6MAOy9VqHTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df.dropna(subset=['Label'], inplace = True)"
      ],
      "metadata": {
        "id": "P1rg9ze0rc9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df.isnull().sum()"
      ],
      "metadata": {
        "id": "2RN36romr2VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df.head(50)"
      ],
      "metadata": {
        "id": "-RGYoYTTr36J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df.to_csv('name-apps.csv', index=False)"
      ],
      "metadata": {
        "id": "TElfy88ssBzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Pre-Processing"
      ],
      "metadata": {
        "id": "48gP24R-sQGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/name-apps.csv')\n",
        "df.head(50)"
      ],
      "metadata": {
        "id": "B2kobbhxsrIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Case Folding"
      ],
      "metadata": {
        "id": "FFY0vG61tNqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def clean_text(df, text_field, new_text_field_name):\n",
        "  my_df[new_text_field_name] = my_df[text_field].str.lower()\n",
        "  my_df[new_text_field_name] = my_df[new_text_field_name].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))\n",
        "\n",
        "  my_df[new_text_field_name] = my_df[new_text_field_name].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
        "  return my_df"
      ],
      "metadata": {
        "id": "lT6tUAwMtYhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_df['text_clean'] = my_df['content'].str.lower()\n",
        "my_df['text_clean']\n",
        "data_clean = clean_text(my_df, 'content', 'text_clean')\n",
        "data_clean.head(10)"
      ],
      "metadata": {
        "id": "HATPiApktT0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stopword Removal"
      ],
      "metadata": {
        "id": "90dz5I42viGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.corpus\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('indonesian') # you can modify this to your language\n",
        "\n",
        "data_clean['text_Stopword'] = data_clean['text_clean'].apply(lambda x:' '.join([word for word in x.split() if word not in (stop)]))\n",
        "data_clean.head(50)"
      ],
      "metadata": {
        "id": "_piD_4AGvoBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenizing"
      ],
      "metadata": {
        "id": "0PLCjb5Zwo94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "data_clean['text_tokens'] = data_clean['text_Stopword'].apply(lambda x: word_tokenize(x))\n",
        "data_clean.head()"
      ],
      "metadata": {
        "id": "BiJQqx-AwteQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stemming (for Indonesian language)"
      ],
      "metadata": {
        "id": "p4_gX-0xxxMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Sastrawi"
      ],
      "metadata": {
        "id": "3MZBquXQx38g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()"
      ],
      "metadata": {
        "id": "viJdSiBDyBdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stemmed_wrapper(term):\n",
        "  return stemmer.stem(term)\n",
        "\n",
        "term_dict = {}\n",
        "hitung = 0\n",
        "\n",
        "for document in data_clean['text_tokens']:\n",
        "  for term in document:\n",
        "    if term not in term_dict:\n",
        "      term_dict[term] = ' '\n",
        "\n",
        "print(len(term_dict))\n",
        "print(\"------------------------\")\n",
        "\n",
        "for term in term_dict:\n",
        "  term_dict[term] = stemmed_wrapper(term)\n",
        "  hitung += 1\n",
        "  print(hitung, \":\", term, \":\", term_dict[term])\n",
        "\n",
        "print(term_dict)\n",
        "print(\"------------------------\")\n",
        "\n",
        "def get_stemmed_term(document):\n",
        "  return [term_dict[term] for term in document]\n",
        "\n",
        "data_clean['text_steamindo'] = data_clean['text_tokens'].apply(lambda x:' '.join(get_stemmed_term(x)))\n",
        "data_clean.head(20)"
      ],
      "metadata": {
        "id": "S5ZJn0hyyUIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean.to_csv('result_TextPreProcessing_nameapp.csv', index=False)"
      ],
      "metadata": {
        "id": "hfF2CorE7O8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TF-IDF"
      ],
      "metadata": {
        "id": "eqkwE7347iuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "ULBUbIe97exU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def praproses(text):\n",
        "  text.re.sub('<[^>]*>', '', text)\n",
        "  emoticons = re.findall('(?::|;|=)()(?:-)?(?:\\)\\(|D|P)', text)\n",
        "  text = (re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', ''))\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "ora1z0X97-xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_clean['content'], data_clean['Label'], test_size=0.20, random_state=0)"
      ],
      "metadata": {
        "id": "UhuDwEno9C-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "tfidf_test = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "OD2czYVm9b6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "6nJQGYpU-L9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(X_train)"
      ],
      "metadata": {
        "id": "YBoKZWcd-gp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = vectorizer.transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "wVb8HCVU-5VP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb = MultinomialNB()\n",
        "nb.fit(tfidf_train, y_train)"
      ],
      "metadata": {
        "id": "qS8JDiYY_KKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.toarray()"
      ],
      "metadata": {
        "id": "YqyFWfmf_d62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = nb.predict(tfidf_test)"
      ],
      "metadata": {
        "id": "ZFYG-jsO_nk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "L-LZrmfG_u8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "predicted = clf.predict(X_test)\n",
        "\n",
        "print(\"MultinomialNB Accuracy:\", accuracy_score(y_test, predicted))\n",
        "print(\"MultinomialNB Precission:\", precision_score(y_test, predicted, average=\"binary\", pos_label=\"Negatif\"))\n",
        "print(\"MultinomialNB Recall:\", recall_score(y_test, predicted, average=\"binary\", pos_label=\"Negatif\"))\n",
        "print(\"MultinomialNB f1_score:\", f1_score(y_test, predicted, average=\"binary\", pos_label=\"Negatif\"))\n",
        "\n",
        "print(f'confussion_matrix:\\n {confusion_matrix(y_test, predicted)}')\n",
        "print('=====================================================\\n')\n",
        "print(classification_report(y_test, predicted, zero_division=0))\n",
        "\n",
        "data_clean = pd.read_csv('result_TextPreProcessing_nameapp.csv')\n"
      ],
      "metadata": {
        "id": "taKJxNco_6nc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}